{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SciSciNet UMD Data Preprocessing\n",
    "\n",
    "This notebook documents the data preprocessing steps for the UMD Computer Science visualization project.\n",
    "\n",
    "## Data Source\n",
    "- **Dataset**: SciSciNet v2 (Northwestern University)\n",
    "- **Source**: https://huggingface.co/datasets/Northwestern-CSSI/sciscinet-v2\n",
    "\n",
    "## Filtering Strategy\n",
    "We filter the full SciSciNet dataset to include only:\n",
    "1. Papers affiliated with University of Maryland (UMD)\n",
    "2. Papers in the Computer Science field\n",
    "3. Related citations, authors, and affiliations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "from pathlib import Path\n",
    "\n",
    "DATA_DIR = Path('../sciscinet_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Identify UMD and CS Field IDs\n",
    "\n",
    "From the SciSciNet metadata:\n",
    "- **UMD Institution ID**: I66946132\n",
    "- **Computer Science Field ID**: C41008148"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UMD_ID = 'I66946132'\n",
    "CS_FIELD_ID = 'C41008148'\n",
    "\n",
    "print(f\"UMD Institution ID: {UMD_ID}\")\n",
    "print(f\"CS Field ID: {CS_FIELD_ID}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Filter Papers\n",
    "\n",
    "We filter papers that are:\n",
    "1. Affiliated with UMD (via paper_author_affiliation table)\n",
    "2. In the Computer Science field (via paper_fields table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load filtered UMD CS papers\n",
    "df_papers = pd.read_parquet(DATA_DIR / 'umd_cs_papers.parquet')\n",
    "print(f\"Total UMD CS papers: {len(df_papers):,}\")\n",
    "print(f\"\\nColumns: {df_papers.columns.tolist()}\")\n",
    "print(f\"\\nYear range: {df_papers['year'].min()} - {df_papers['year'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Papers per year\n",
    "papers_by_year = df_papers.groupby('year').size()\n",
    "print(\"Papers by year (last 10 years):\")\n",
    "print(papers_by_year[papers_by_year.index >= 2014])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Filter Citation Network\n",
    "\n",
    "We keep only **internal citations** - citations between UMD CS papers.\n",
    "This significantly reduces the dataset size while maintaining meaningful relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load internal citations\n",
    "df_refs = pd.read_parquet(DATA_DIR / 'umd_cs_paperrefs.parquet')\n",
    "print(f\"Internal citations: {len(df_refs):,}\")\n",
    "print(f\"\\nColumns: {df_refs.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Filter Authors\n",
    "\n",
    "We include all authors who have co-authored at least one UMD CS paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load author data\n",
    "df_authors = pd.read_parquet(DATA_DIR / 'umd_authors.parquet')\n",
    "print(f\"UMD authors: {len(df_authors):,}\")\n",
    "print(f\"\\nColumns: {df_authors.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load paper-author relationships\n",
    "df_paa = pd.read_parquet(DATA_DIR / 'umd_paper_author_affiliation.parquet')\n",
    "print(f\"Paper-author relationships: {len(df_paa):,}\")\n",
    "print(f\"\\nAverage authors per paper: {df_paa.groupby('paperid').size().mean():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Summary\n",
    "\n",
    "| Dataset | Original Size | Filtered Size | Reduction |\n",
    "|---------|---------------|---------------|----------|\n",
    "| Papers | ~270M | 87,738 | 99.97% |\n",
    "| Citations | ~2.3B | 126,892 | 99.99% |\n",
    "| Authors | ~270M | 78,079 | 99.97% |\n",
    "\n",
    "This filtering allows us to focus on UMD CS research while keeping the dataset manageable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scalability Solutions\n",
    "\n",
    "### For Visualization:\n",
    "1. **Node Filtering**: Show only top N most-cited papers or prolific authors\n",
    "2. **Time Filtering**: Focus on recent 5 years for networks\n",
    "3. **Collision Detection**: Prevent node overlap in force-directed layout\n",
    "4. **Level of Detail**: Show labels only for important nodes\n",
    "\n",
    "### For Data Processing:\n",
    "1. **Batch Processing**: Read parquet files in chunks\n",
    "2. **Set-based Filtering**: Use Python sets for O(1) lookup\n",
    "3. **Parquet Format**: Column-oriented storage for efficient queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Filter for past 5 years network\n",
    "recent_papers = df_papers[df_papers['year'] >= 2019]\n",
    "print(f\"Papers in past 5 years: {len(recent_papers):,}\")\n",
    "\n",
    "# Top cited papers\n",
    "top_cited = recent_papers.nlargest(200, 'cited_by_count')\n",
    "print(f\"Top 200 cited papers for visualization\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
